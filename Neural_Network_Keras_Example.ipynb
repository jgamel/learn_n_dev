{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_Keras_Example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9WKoqxYKza3y4WKsEj1+E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jgamel/learn_n_dev/blob/python_machine_learning/Neural_Network_Keras_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Example"
      ],
      "metadata": {
        "id": "aWJJSdjPOcBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps:\n",
        "\n",
        "1. Haberman Breast Cancer Survival Dataset\n",
        "2. Neural Network Learning Dynamics\n",
        "3. Robust Model Evaluation\n",
        "4. Final Model and Make Predictions"
      ],
      "metadata": {
        "id": "AW1zKyh3OhHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Load Data and Prep"
      ],
      "metadata": {
        "id": "OT597IMHPLxZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Haberman Breast Cancer Survival Dataset\n",
        "The first step is to define and explore the dataset.\n",
        "\n",
        "We will be working with the “haberman” standard binary classification dataset.\n",
        "\n",
        "The dataset describes breast cancer patient data and the outcome is patient survival. Specifically whether the patient survived for five years or longer, or whether the patient did not survive.\n",
        "\n",
        "This is a standard dataset used in the study of imbalanced classification. According to the dataset description, the operations were conducted between 1958 and 1970 at the University of Chicago’s Billings Hospital.\n",
        "\n",
        "There are 306 examples in the dataset, and there are 3 input variables; they are:\n",
        "\n",
        "The age of the patient at the time of the operation.\n",
        "The two-digit year of the operation.\n",
        "The number of “positive axillary nodes” detected, a measure of whether cancer has spread.\n",
        "As such, we have no control over the selection of cases that make up the dataset or features to use in those cases, other than what is available in the dataset.\n",
        "\n",
        "Although the dataset describes breast cancer patient survival, given the small dataset size and the fact the data is based on breast cancer diagnosis and operations many decades ago, any models built on this dataset are not expected to generalize."
      ],
      "metadata": {
        "id": "pk71r7cBPGM3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWW7Uv-KNQsU",
        "outputId": "87d5c6ec-1da0-4b4e-b68b-d81bbf283830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(306, 4)\n"
          ]
        }
      ],
      "source": [
        "# load the haberman dataset and summarize the shape\n",
        "from pandas import read_csv\n",
        "# define the location of the dataset\n",
        "url = 'https://raw.githubusercontent.com/jgamel/learn_n_dev/input_data/haberman.csv'\n",
        "# load the dataset\n",
        "df = read_csv(url, header=None)\n",
        "# summarize shape\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example loads the dataset directly from the URL and reports the shape of the dataset.\n",
        "\n",
        "In this case, we can confirm that the dataset has 4 variables (3 input and one output) and that the dataset has 306 rows of data.\n",
        "\n",
        "This is not many rows of data for a neural network and suggests that a small network, perhaps with regularization, would be appropriate.\n",
        "\n",
        "It also suggests that using k-fold cross-validation would be a good idea given that it will give a more reliable estimate of model performance than a train/test split and because a single model will fit in seconds instead of hours or days with the largest datasets."
      ],
      "metadata": {
        "id": "JMopAqy6PjBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can learn more about the dataset by looking at summary statistics and a plot of the data."
      ],
      "metadata": {
        "id": "CyBohVCzPm5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show summary statistics and plots of the haberman dataset\n",
        "from pandas import read_csv\n",
        "from matplotlib import pyplot\n",
        "# define the location of the dataset\n",
        "url = 'https://raw.githubusercontent.com/jgamel/learn_n_dev/input_data/haberman.csv'\n",
        "# load the dataset\n",
        "df = read_csv(url, header=None)\n",
        "# show summary statistics\n",
        "print(df.describe())\n",
        "# plot histograms\n",
        "df.hist()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "oBfAy757Pnqe",
        "outputId": "d17d11d6-cede-41ec-ea59-cd6eaff17f06"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                0           1           2           3\n",
            "count  306.000000  306.000000  306.000000  306.000000\n",
            "mean    52.457516   62.852941    4.026144    1.264706\n",
            "std     10.803452    3.249405    7.189654    0.441899\n",
            "min     30.000000   58.000000    0.000000    1.000000\n",
            "25%     44.000000   60.000000    0.000000    1.000000\n",
            "50%     52.000000   63.000000    1.000000    1.000000\n",
            "75%     60.750000   65.750000    4.000000    2.000000\n",
            "max     83.000000   69.000000   52.000000    2.000000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example first loads the data before and then prints summary statistics for each variable.\n",
        "\n",
        "We can see that values vary with different means and standard deviations, perhaps some normalization or standardization would be required prior to modeling.\n",
        "\n",
        "A histogram plot is then created for each variable.\n",
        "\n",
        "We can see that perhaps the first variable has a Gaussian-like distribution and the next two input variables may have an exponential distribution.\n",
        "\n",
        "We may have some benefit in using a power transform on each variable in order to make the probability distribution less skewed which will likely improve model performance."
      ],
      "metadata": {
        "id": "ihGGHUzYQGjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see some skew in the distribution of examples between the two classes, meaning that the classification problem is not balanced. It is imbalanced.\n",
        "\n",
        "It may be helpful to know how imbalanced the dataset actually is.\n",
        "\n",
        "We can use the Counter object to count the number of examples in each class, then use those counts to summarize the distribution.\n",
        "\n",
        "The complete example is listed below."
      ],
      "metadata": {
        "id": "0iT7gZluQunV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the class ratio of the haberman dataset\n",
        "from pandas import read_csv\n",
        "from collections import Counter\n",
        "# define the location of the dataset\n",
        "url = 'https://raw.githubusercontent.com/jgamel/learn_n_dev/input_data/haberman.csv'\n",
        "# define the dataset column names\n",
        "columns = ['age', 'year', 'nodes', 'class']\n",
        "# load the csv file as a data frame\n",
        "dataframe = read_csv(url, header=None, names=columns)\n",
        "# summarize the class distribution\n",
        "target = dataframe['class'].values\n",
        "counter = Counter(target)\n",
        "for k,v in counter.items():\n",
        "\tper = v / len(target) * 100\n",
        "\tprint('Class=%d, Count=%d, Percentage=%.3f%%' % (k, v, per))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtlluGN_Q0T4",
        "outputId": "c6002b24-d71b-4069-9a97-41fdf6facb39"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class=1, Count=225, Percentage=73.529%\n",
            "Class=2, Count=81, Percentage=26.471%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that class 1 for survival has the most examples at 225, or about 74 percent of the dataset. We can see class 2 for non-survival has fewer examples at 81, or about 26 percent of the dataset.\n",
        "\n",
        "The class distribution is skewed, but it is not severely imbalanced.\n",
        "\n",
        "This is helpful because if we use classification accuracy, then any model that achieves an accuracy less than about 73.5% does not have skill on this dataset.\n",
        "\n",
        "Now that we are familiar with the dataset, let’s explore how we might develop a neural network model."
      ],
      "metadata": {
        "id": "PN7h7EZ_QvaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network Learning Dynamics"
      ],
      "metadata": {
        "id": "nOEaso7DXSd2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will develop a **Multilayer Perceptron (MLP) model** for the dataset using TensorFlow.\n",
        "\n",
        "We cannot know what model architecture of learning hyperparameters would be good or best for this dataset, so we must experiment and discover what works well.\n",
        "\n",
        "Given that the dataset is small, a small batch size is probably a good idea, e.g. 16 or 32 rows. Using the Adam version of stochastic gradient descent is a good idea when getting started as it will automatically adapt the learning rate and works well on most datasets.\n",
        "\n",
        "Before we evaluate models in earnest, it is a good idea to review the learning dynamics and tune the model architecture and learning configuration until we have stable learning dynamics, then look at getting the most out of the model.\n",
        "\n",
        "We can do this by using a simple train/test split of the data and review plots of the learning curves. This will help us see if we are over-learning or under-learning; then we can adapt the configuration accordingly.\n",
        "\n",
        "First, we must ensure all input variables are floating-point values and encode the target label as integer values 0 and 1."
      ],
      "metadata": {
        "id": "eFQOpuaNXTkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit a simple mlp model on the haberman and review learning curves\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "# load the dataset\n",
        "path = 'https://raw.githubusercontent.com/jgamel/learn_n_dev/input_data/haberman.csv'\n",
        "df = read_csv(path, header=None)\n",
        "# split into input and output columns\n",
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "# ensure all data are floating point values\n",
        "X = X.astype('float32')\n",
        "# encode strings to integer\n",
        "y = LabelEncoder().fit_transform(y)"
      ],
      "metadata": {
        "id": "21WuffATYKsv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can split the dataset into input and output variables, then into 67/33 train and test sets.\n",
        "\n",
        "We must ensure that the split is stratified by the class ensuring that the train and test sets have the same distribution of class labels as the main dataset."
      ],
      "metadata": {
        "id": "wWFokgUhY5Bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y, random_state=3)"
      ],
      "metadata": {
        "id": "G9rNbc5AZcbC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can define a minimal MLP model. In this case, we will use one hidden layer with 10 nodes and one output layer (chosen arbitrarily). We will use the ReLU activation function in the hidden layer and the “he_normal” weight initialization, as together, they are a good practice.\n",
        "\n",
        "The output of the model is a sigmoid activation for binary classification and we will minimize binary cross-entropy loss."
      ],
      "metadata": {
        "id": "ZE8YBSjWZkad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# determine the number of input features\n",
        "n_features = X.shape[1]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "HHbEs_wQZten"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will fit the model for 200 training epochs (chosen arbitrarily) with a batch size of 16 because it is a small dataset.\n",
        "\n",
        "We are fitting the model on raw data, which we think might be a good idea, but it is an important starting point."
      ],
      "metadata": {
        "id": "_EEtq2WsZzeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "history = model.fit(X_train, y_train, epochs=200, batch_size=16, verbose=0, validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "id": "hI6d2puWaASJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the end of training, we will evaluate the model’s performance on the test dataset and report performance as the classification accuracy."
      ],
      "metadata": {
        "id": "FDs5ErVBaH_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# predict test set\n",
        "yhat = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "# yhat = np.argmax(model.predict(X_test), axis=-1)\n",
        "# yhat = model.predict_classes(X_test)\n",
        "# evaluate predictions\n",
        "score = accuracy_score(y_test, yhat)\n",
        "print('Accuracy: %.3f' % score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMj8bBPPaLWm",
        "outputId": "bf1ceefb-02f2-4f38-ee2d-7af075058de1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will plot learning curves of the cross-entropy loss on the train and test sets during training."
      ],
      "metadata": {
        "id": "MMYeiw0fcFwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot learning curves\n",
        "pyplot.title('Learning Curves')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Cross Entropy')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0uV8JHFRcILM",
        "outputId": "9192d75e-a043-42e2-a79f-241a26c024f7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example first fits the model on the training dataset, then reports the classification accuracy on the test dataset.\n",
        "\n",
        "Line plots of the loss on the train and test sets are then created.\n",
        "\n",
        "We can see that the model quickly finds a good fit on the dataset and does not appear to be over or underfitting.\n",
        "\n",
        "Now that we have some idea of the learning dynamics for a simple MLP model on the dataset, we can look at developing a more robust evaluation of model performance on the dataset."
      ],
      "metadata": {
        "id": "2PLdTJW1dStI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Robust Model Evaluation"
      ],
      "metadata": {
        "id": "ZkzdPdBxdkAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The k-fold cross-validation procedure can provide a more reliable estimate of MLP performance, although it can be very slow.\n",
        "\n",
        "This is because k models must be fit and evaluated. This is not a problem when the dataset size is small, such as the cancer survival dataset.\n",
        "\n",
        "We can use the StratifiedKFold class and enumerate each fold manually, fit the model, evaluate it, and then report the mean of the evaluation scores at the end of the procedure."
      ],
      "metadata": {
        "id": "VML3sE_ldrZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# k-fold cross-validation of base model for the haberman dataset\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "# load the dataset\n",
        "path = 'https://raw.githubusercontent.com/jgamel/learn_n_dev/input_data/haberman.csv'\n",
        "df = read_csv(path, header=None)\n",
        "# split into input and output columns\n",
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "# ensure all data are floating point values\n",
        "X = X.astype('float32')\n",
        "# encode strings to integer\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "# prepare cross validation\n",
        "kfold = StratifiedKFold(10, random_state=1, shuffle=True)\n",
        "# enumerate splits\n",
        "scores = list()\n",
        "for train_ix, test_ix in kfold.split(X, y):\n",
        "\t# split data\n",
        "\tX_train, X_test, y_train, y_test = X[train_ix], X[test_ix], y[train_ix], y[test_ix]\n",
        "\t# determine the number of input features\n",
        "\tn_features = X.shape[1]\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile the model\n",
        "\tmodel.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\t# fit the model\n",
        "\tmodel.fit(X_train, y_train, epochs=200, batch_size=16, verbose=0)\n",
        "\t# predict test set\n",
        "\t# yhat = np.argmax(model.predict(X_test), axis=-1)\n",
        "\tyhat = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "  # evaluate predictions\n",
        "\tscore = accuracy_score(y_test, yhat)\n",
        "\tprint('>%.3f' % score)\n",
        "\tscores.append(score)\n",
        "# summarize all scores\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0kKRFK0dupT",
        "outputId": "d2d960fd-4abb-4cbc-90a5-c599cedecee4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">0.710\n",
            ">0.742\n",
            ">0.774\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fab1b4acef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            ">0.806\n",
            "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fab1b300050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            ">0.710\n",
            ">0.742\n",
            ">0.833\n",
            ">0.700\n",
            ">0.667\n",
            ">0.800\n",
            "Mean Accuracy: 0.748 (0.051)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are using TensorFlow version 2.5, you will receive the following warning:\n",
        "\n",
        "tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: model.predict_classes() is deprecated and will be removed after 2021-01-01. Please use instead:* np.argmax(model.predict(x), axis=-1), if your model does multi-class classification (e.g. if it uses a softmax last-layer activation).* (model.predict(x) > 0.5).astype(\"int32\"), if your model does binary classification (e.g. if it uses a sigmoid last-layer activation)."
      ],
      "metadata": {
        "id": "_yA3w2Vqz_vf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is this a good result?\n",
        "\n",
        "In fact, this is a challenging classification problem and achieving a score above about 74.5% is good.\n",
        "\n",
        "Next, let’s look at how we might fit a final model and use it to make predictions."
      ],
      "metadata": {
        "id": "bnldPswu0Uxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Model and Make Predictions"
      ],
      "metadata": {
        "id": "f2S8XuNa0X9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we choose a model configuration, we can train a final model on all available data and use it to make predictions on new data.\n",
        "\n",
        "In this case, we will use the model with dropout and a small batch size as our final model.\n",
        "\n",
        "We can prepare the data and fit the model as before, although on the entire dataset instead of a training subset of the dataset."
      ],
      "metadata": {
        "id": "HUNt4wh60Y_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we can define a row of new data."
      ],
      "metadata": {
        "id": "yFykY02k1REP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a row of new data\n",
        "row = [30,64,1]"
      ],
      "metadata": {
        "id": "bFe_d8Ei1UOK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: I took this row from the first row of the dataset and the expected label is a ‘1’.\n",
        "\n",
        "We can then make a prediction."
      ],
      "metadata": {
        "id": "T0RDTBKz1Y_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "#yhat = model.predict_classes([row])\n",
        "yhat = (model.predict([row]) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "id": "-zG6qi0k1bXt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then invert the transform on the prediction, so we can use or interpret the result in the correct label (which is just an integer for this dataset)."
      ],
      "metadata": {
        "id": "sA0zeEYm1thN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit a final model and make predictions on new data for the haberman dataset\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "# load the dataset\n",
        "path = 'https://raw.githubusercontent.com/jgamel/learn_n_dev/input_data/haberman.csv'\n",
        "df = read_csv(path, header=None)\n",
        "# split into input and output columns\n",
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "# ensure all data are floating point values\n",
        "X = X.astype('float32')\n",
        "# encode strings to integer\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "# determine the number of input features\n",
        "n_features = X.shape[1]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=200, batch_size=16, verbose=0)\n",
        "# define a row of new data\n",
        "row = [30,64,1]\n",
        "# make prediction\n",
        "yhat = (model.predict([row]) > 0.5).astype(\"int32\")\n",
        "# invert transform to get label for class\n",
        "yhat = le.inverse_transform(yhat)\n",
        "# report prediction\n",
        "print('Predicted: %s' % (yhat[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Chbe6ZuI1uad",
        "outputId": "d3015ab4-d05a-4573-fbff-9b8c50212080"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example fits the model on the entire dataset and makes a prediction for a single row of new data.\n",
        "\n",
        "In this case, we can see that the model predicted a “1” label for the input row."
      ],
      "metadata": {
        "id": "10ObfNzbafeB"
      }
    }
  ]
}